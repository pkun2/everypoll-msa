from threading import Lock
from typing import List, Dict, Any, Optional, Literal
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain_core.messages import BaseMessage, AIMessage, HumanMessage, ToolMessage, AnyMessage
from langchain_core.tools import BaseTool, tool
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.documents import Document
from langchain_core.vectorstores import InMemoryVectorStore
from langgraph.graph import StateGraph, START, END
from typing_extensions import TypedDict, Annotated
import json
import uuid
import operator
import os

app = FastAPI(title="RAG Agent API")

EMBEDDING_API_URL = os.getenv("EMBEDDING_API_URL", "http://localhost:8000/v1")
LLM_API_URL = os.getenv("LLM_API_URL", "http://localhost:8001/v1")

print(f"ğŸ”§ Embedding API: {EMBEDDING_API_URL}")
print(f"ğŸ”§ LLM API: {LLM_API_URL}")

embedding_model = OpenAIEmbeddings(
    model="BAAI/bge-m3",
    openai_api_base=EMBEDDING_API_URL,
    openai_api_key="dummy"
)

print("âœ… ì„ë² ë”© ëª¨ë¸ ì—°ê²° ì™„ë£Œ")

class DocumentManager:
    def __init__(self):
        self.documents: List[Document] = []
        self.current_index: int = 0
        self.lock = Lock()
    
    def add_documents(self, contents: List[str], source: str = "api") -> List[Document]:
        """ë¬¸ì„œ ì¶”ê°€ ë° ì¸ë±ì‹±"""
        with self.lock:
            new_docs = []
            for content in contents:
                doc = Document(
                    page_content=content,
                    metadata={
                        "source": source,
                        "index": self.current_index,
                        "id": str(uuid.uuid4())
                    }
                )
                new_docs.append(doc)
                self.documents.append(doc)
                self.current_index += 1
            return new_docs
    
    def get_all_documents(self) -> List[Document]:
        """ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ"""
        return self.documents
    
    def get_document_count(self) -> int:
        """ë¬¸ì„œ ìˆ˜ ì¡°íšŒ"""
        return len(self.documents)
    
    def delete_document(self, doc_id: str) -> bool:
        """ë¬¸ì„œ ì‚­ì œ (ID ê¸°ë°˜)"""
        with self.lock:
            for i, doc in enumerate(self.documents):
                if doc.metadata.get("id") == doc_id:
                    self.documents.pop(i)
                    return True
            return False

# ë¬¸ì„œ ê´€ë¦¬ì ì¸ìŠ¤í„´ìŠ¤
doc_manager = DocumentManager()

sentences = [
    "ë°˜í’ˆì€ êµ¬ë§¤ í›„ 30ì¼ ì´ë‚´ì—ë§Œ ê°€ëŠ¥í•˜ë©°, ì˜ìˆ˜ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.",
    "ë°°ì†¡ì€ í‰ì¼ ê¸°ì¤€ 2~3ì¼ ì†Œìš”ë˜ë©°, ë„ì„œ ì‚°ê°„ ì§€ì—­ì€ í•˜ë£¨ ë” ê±¸ë¦½ë‹ˆë‹¤.",
    "íšŒì› ê°€ì… ì‹œ 10% í• ì¸ ì¿ í°ì„ ì¦‰ì‹œ ì§€ê¸‰í•©ë‹ˆë‹¤.",
    "ê³ ê° ì„¼í„° ìš´ì˜ ì‹œê°„ì€ ì˜¤ì „ 9ì‹œë¶€í„° ì˜¤í›„ 6ì‹œê¹Œì§€ì…ë‹ˆë‹¤.",
    "í™˜ë¶ˆì€ ê³„ì¢Œ ì´ì²´ë¡œ ì²˜ë¦¬ë˜ë©°, 3~5 ì˜ì—…ì¼ ì†Œìš”ë©ë‹ˆë‹¤.",
    "ë¬´ë£Œ ë°°ì†¡ì€ 3ë§Œì› ì´ìƒ êµ¬ë§¤ ì‹œ ì ìš©ë©ë‹ˆë‹¤.",
    "ì£¼ë§ ë° ê³µíœ´ì¼ì—ëŠ” ê³ ê°ì„¼í„°ê°€ ìš´ì˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
    "ì œí’ˆ í•˜ì ì‹œ ì „ì•¡ í™˜ë¶ˆ ë˜ëŠ” êµí™˜ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
]

initial_docs = doc_manager.add_documents(sentences, source="manual")

print(f"ğŸ“š {len(initial_docs)}ê°œ ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ë¡œë“œ ì¤‘...")

vectorstore = InMemoryVectorStore.from_documents(
    documents=initial_docs,
    embedding=embedding_model
)

print(f"âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ ({doc_manager.get_document_count()}ê°œ ë¬¸ì„œ)")

retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 3}
)

@tool
def retrieve_blog_posts(query: str) -> str:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ íšŒì‚¬ ë§¤ë‰´ì–¼ ë‚´ìš©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰í•  ì§ˆë¬¸ ë‚´ìš©
    """
    print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
    docs = retriever.invoke(query)
    print(f"ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")
    return "\n\n".join([doc.page_content for doc in docs])

retriever_tool = retrieve_blog_posts

llm = ChatOpenAI(
    model="pkun2/qwen3_4bit_mixed_kr_2_gptq",
    openai_api_base=LLM_API_URL,
    openai_api_key="dummy",
    temperature=0.7,
    max_tokens=2048
)

print("âœ… LLM ì—°ê²° ì™„ë£Œ")

tools = [retrieve_blog_posts]
tools_by_name = {tool.name: tool for tool in tools}
llm_with_tools = llm.bind_tools(tools)

class MessagesState(TypedDict):
    messages: Annotated[list[AnyMessage], operator.add]

def should_continue(state: MessagesState) -> Literal["tool_node", "end"]:
    messages = state["messages"]
    last_message = messages[-1]
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tool_node"
    return "end"

def llm_call(state: MessagesState):
    """LLM í˜¸ì¶œ"""
    response = llm_with_tools.invoke(state["messages"])
    return {"messages": [response]}

from langgraph.prebuilt import ToolNode
tool_node = ToolNode(tools)

# ê·¸ë˜í”„ ë¹Œë“œ
agent_builder = StateGraph(MessagesState)
agent_builder.add_node("llm_call", llm_call)
agent_builder.add_node("tool_node", tool_node)
agent_builder.add_edge(START, "llm_call")
agent_builder.add_conditional_edges(
    "llm_call",
    should_continue,
    {
        "tool_node": "tool_node",
        "end": END
    }
)
agent_builder.add_edge("tool_node", "llm_call")

agent = agent_builder.compile()

print("âœ… LangGraph ì—ì´ì „íŠ¸ ë¹Œë“œ ì™„ë£Œ")

class ChatRequest(BaseModel):
    query: str
    conversation_id: Optional[str] = "default"

class ChatResponse(BaseModel):
    answer: str
    sources: List[str]

class AddDocumentsRequest(BaseModel):
    documents: List[str]
    source: Optional[str] = "api"

class AddDocumentsResponse(BaseModel):
    message: str
    added_count: int
    total_count: int
    documents: List[Dict[str, Any]]

class DocumentResponse(BaseModel):
    id: str
    content: str
    source: str
    index: int

class SearchResult(BaseModel):
    content: str
    metadata: Dict[str, Any]
    score: Optional[float] = None

@app.get("/health")
def health():
    """í—¬ìŠ¤ì²´í¬"""
    return {
        "status": "healthy",
        "embedding_api": EMBEDDING_API_URL,
        "llm_api": LLM_API_URL,
        "documents_count": doc_manager.get_document_count()
    }

@app.post("/api/v1/chat", response_model=ChatResponse)
def chat(request: ChatRequest):
    """RAG ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸"""
    try:
        print(f"\n{'='*50}")
        print(f"ğŸ’¬ ì§ˆë¬¸: {request.query}")
        print(f"ğŸ†” ëŒ€í™” ID: {request.conversation_id}")
        
        # ì—ì´ì „íŠ¸ ì‹¤í–‰
        messages = [HumanMessage(content=request.query)]
        result = agent.invoke({"messages": messages})
        
        # ìµœì¢… ë‹µë³€ ì¶”ì¶œ
        final_message = result["messages"][-1]
        answer = final_message.content
        
        # ê²€ìƒ‰ëœ ì†ŒìŠ¤ ì¶”ì¶œ
        sources = []
        for msg in result["messages"]:
            if isinstance(msg, ToolMessage):
                sources.append(msg.content)
        
        print(f"âœ… ë‹µë³€: {answer}")
        print(f"ğŸ“š ì†ŒìŠ¤ ê°œìˆ˜: {len(sources)}")
        print(f"{'='*50}\n")
        
        return ChatResponse(
            answer=answer,
            sources=sources
        )
    
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/documents", response_model=AddDocumentsResponse)
def add_documents(request: AddDocumentsRequest):
    """ë¬¸ì„œ ì¶”ê°€ (ëŸ°íƒ€ì„ì— ì¶”ê°€)"""
    try:
        new_docs = doc_manager.add_documents(
            contents=request.documents,
            source=request.source
        )
        
        # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
        vectorstore.add_documents(new_docs)
        
        added_docs_info = [
            {
                "id": doc.metadata["id"],
                "content": doc.page_content,
                "source": doc.metadata["source"],
                "index": doc.metadata["index"]
            }
            for doc in new_docs
        ]
        
        print(f"ğŸ“ {len(new_docs)}ê°œ ë¬¸ì„œ ì¶”ê°€ë¨ (ì´ {doc_manager.get_document_count()}ê°œ)")
        
        return AddDocumentsResponse(
            message=f"{len(new_docs)}ê°œ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ",
            added_count=len(new_docs),
            total_count=doc_manager.get_document_count(),
            documents=added_docs_info
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/search")
def search(query: str, k: int = 3):
    """ì§ì ‘ ê²€ìƒ‰"""
    try:
        docs = vectorstore.similarity_search(query, k=k)
        
        return {
            "query": query,
            "k": k,
            "results_count": len(docs),
            "results": [
                {
                    "content": doc.page_content,
                    "metadata": doc.metadata
                }
                for doc in docs
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/documents")
def list_documents():
    """ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡"""
    all_docs = doc_manager.get_all_documents()
    return {
        "total": len(all_docs),
        "documents": [
            {
                "id": doc.metadata.get("id"),
                "content": doc.page_content,
                "source": doc.metadata.get("source"),
                "index": doc.metadata.get("index")
            }
            for doc in all_docs
        ]
    }
    
@app.delete("/api/v1/documents/{doc_id}")
def delete_document(doc_id: str):
    """ë¬¸ì„œ ì‚­ì œ"""
    try:
        success = doc_manager.delete_document(doc_id)
        if success:
            return {
                "message": f"ë¬¸ì„œ {doc_id} ì‚­ì œ ì™„ë£Œ",
                "total_count": doc_manager.get_document_count()
            }
        else:
            raise HTTPException(status_code=404, detail=f"ë¬¸ì„œ {doc_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )
