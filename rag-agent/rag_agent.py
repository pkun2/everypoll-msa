from typing import List, Dict, Any, Optional, Literal
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from langchain_core.messages import BaseMessage, AIMessage, HumanMessage, ToolMessage, AnyMessage
from langchain_core.tools import BaseTool, tool
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_core.documents import Document
from langchain_core.vectorstores import InMemoryVectorStore
from langgraph.graph import StateGraph, START, END
from typing_extensions import TypedDict, Annotated
import json
import uuid
import operator
import os

app = FastAPI(title="RAG Agent API")

EMBEDDING_API_URL = os.getenv("EMBEDDING_API_URL", "http://localhost:8000/v1")
LLM_API_URL = os.getenv("LLM_API_URL", "http://localhost:8001/v1")

print(f"ğŸ”§ Embedding API: {EMBEDDING_API_URL}")
print(f"ğŸ”§ LLM API: {LLM_API_URL}")

embedding_model = OpenAIEmbeddings(
    model="BAAI/bge-m3",
    openai_api_base=EMBEDDING_API_URL,
    openai_api_key="dummy"
)

print("âœ… ì„ë² ë”© ëª¨ë¸ ì—°ê²° ì™„ë£Œ")

sentences = [
    "ë°˜í’ˆì€ êµ¬ë§¤ í›„ 30ì¼ ì´ë‚´ì—ë§Œ ê°€ëŠ¥í•˜ë©°, ì˜ìˆ˜ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.",
    "ë°°ì†¡ì€ í‰ì¼ ê¸°ì¤€ 2~3ì¼ ì†Œìš”ë˜ë©°, ë„ì„œ ì‚°ê°„ ì§€ì—­ì€ í•˜ë£¨ ë” ê±¸ë¦½ë‹ˆë‹¤.",
    "íšŒì› ê°€ì… ì‹œ 10% í• ì¸ ì¿ í°ì„ ì¦‰ì‹œ ì§€ê¸‰í•©ë‹ˆë‹¤.",
    "ê³ ê° ì„¼í„° ìš´ì˜ ì‹œê°„ì€ ì˜¤ì „ 9ì‹œë¶€í„° ì˜¤í›„ 6ì‹œê¹Œì§€ì…ë‹ˆë‹¤.",
    "í™˜ë¶ˆì€ ê³„ì¢Œ ì´ì²´ë¡œ ì²˜ë¦¬ë˜ë©°, 3~5 ì˜ì—…ì¼ ì†Œìš”ë©ë‹ˆë‹¤.",
    "ë¬´ë£Œ ë°°ì†¡ì€ 3ë§Œì› ì´ìƒ êµ¬ë§¤ ì‹œ ì ìš©ë©ë‹ˆë‹¤.",
    "ì£¼ë§ ë° ê³µíœ´ì¼ì—ëŠ” ê³ ê°ì„¼í„°ê°€ ìš´ì˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
    "ì œí’ˆ í•˜ì ì‹œ ì „ì•¡ í™˜ë¶ˆ ë˜ëŠ” êµí™˜ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤."
]

langchain_docs = [
    Document(
        page_content=s,
        metadata={"source": "manual", "index": i}
    ) 
    for i, s in enumerate(sentences)
]

print(f"ğŸ“š {len(langchain_docs)}ê°œ ë¬¸ì„œë¥¼ ë²¡í„° ìŠ¤í† ì–´ì— ë¡œë“œ ì¤‘...")

vectorstore = InMemoryVectorStore.from_documents(
    documents=langchain_docs,
    embedding=embedding_model
)

print(f"âœ… ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ì™„ë£Œ ({len(langchain_docs)}ê°œ ë¬¸ì„œ)")

retriever = vectorstore.as_retriever(
    search_type="similarity",
    search_kwargs={"k": 3}
)

@tool
def retrieve_blog_posts(query: str) -> str:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ íšŒì‚¬ ë§¤ë‰´ì–¼ ë‚´ìš©ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰í•  ì§ˆë¬¸ ë‚´ìš©
    """
    print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: {query}")
    docs = retriever.invoke(query)
    print(f"ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")
    return "\n\n".join([doc.page_content for doc in docs])

retriever_tool = retrieve_blog_posts

llm = ChatOpenAI(
    model="pkun2/qwen3_4bit_mixed_kr_2_gptq",
    openai_api_base=LLM_API_URL,
    openai_api_key="dummy",
    temperature=0.7,
    max_tokens=2048
)

print("âœ… LLM ì—°ê²° ì™„ë£Œ")

tools = [retrieve_blog_posts]
tools_by_name = {tool.name: tool for tool in tools}
llm_with_tools = llm.bind_tools(tools)

class MessagesState(TypedDict):
    messages: Annotated[list[AnyMessage], operator.add]

def should_continue(state: MessagesState) -> Literal["tool_node", "end"]:
    messages = state["messages"]
    last_message = messages[-1]
    if hasattr(last_message, "tool_calls") and last_message.tool_calls:
        return "tool_node"
    return "end"

def llm_call(state: MessagesState):
    """LLM í˜¸ì¶œ"""
    response = llm_with_tools.invoke(state["messages"])
    return {"messages": [response]}

from langgraph.prebuilt import ToolNode
tool_node = ToolNode(tools)

# ê·¸ë˜í”„ ë¹Œë“œ
agent_builder = StateGraph(MessagesState)
agent_builder.add_node("llm_call", llm_call)
agent_builder.add_node("tool_node", tool_node)
agent_builder.add_edge(START, "llm_call")
agent_builder.add_conditional_edges(
    "llm_call",
    should_continue,
    {
        "tool_node": "tool_node",
        "end": END
    }
)
agent_builder.add_edge("tool_node", "llm_call")

agent = agent_builder.compile()

print("âœ… LangGraph ì—ì´ì „íŠ¸ ë¹Œë“œ ì™„ë£Œ")

class ChatRequest(BaseModel):
    query: str
    conversation_id: Optional[str] = "default"

class ChatResponse(BaseModel):
    answer: str
    sources: List[str]

@app.get("/health")
def health():
    """í—¬ìŠ¤ì²´í¬"""
    return {
        "status": "healthy",
        "embedding_api": EMBEDDING_API_URL,
        "llm_api": LLM_API_URL,
        "documents_count": len(langchain_docs)
    }

@app.post("/api/v1/chat", response_model=ChatResponse)
def chat(request: ChatRequest):
    """RAG ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸"""
    try:
        print(f"\n{'='*50}")
        print(f"ğŸ’¬ ì§ˆë¬¸: {request.query}")
        print(f"ğŸ†” ëŒ€í™” ID: {request.conversation_id}")
        
        # ì—ì´ì „íŠ¸ ì‹¤í–‰
        messages = [HumanMessage(content=request.query)]
        result = agent.invoke({"messages": messages})
        
        # ìµœì¢… ë‹µë³€ ì¶”ì¶œ
        final_message = result["messages"][-1]
        answer = final_message.content
        
        # ê²€ìƒ‰ëœ ì†ŒìŠ¤ ì¶”ì¶œ
        sources = []
        for msg in result["messages"]:
            if isinstance(msg, ToolMessage):
                sources.append(msg.content)
        
        print(f"âœ… ë‹µë³€: {answer}")
        print(f"ğŸ“š ì†ŒìŠ¤ ê°œìˆ˜: {len(sources)}")
        print(f"{'='*50}\n")
        
        return ChatResponse(
            answer=answer,
            sources=sources
        )
    
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/v1/documents")
def add_documents(documents: List[str]):
    """ë¬¸ì„œ ì¶”ê°€ (ëŸ°íƒ€ì„ì— ì¶”ê°€)"""
    try:
        new_docs = [
            Document(page_content=doc, metadata={"source": "api"})
            for doc in documents
        ]
        
        # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
        vectorstore.add_documents(new_docs)
        
        return {"message": f"{len(new_docs)}ê°œ ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/search")
def search(query: str, k: int = 3):
    """ì§ì ‘ ê²€ìƒ‰"""
    try:
        docs = retriever.invoke(query)
        return {
            "query": query,
            "results": [
                {
                    "content": doc.page_content,
                    "metadata": doc.metadata
                }
                for doc in docs
            ]
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/v1/documents")
def list_documents():
    """ì €ì¥ëœ ë¬¸ì„œ ëª©ë¡"""
    return {
        "total": len(langchain_docs),
        "documents": [
            {
                "content": doc.page_content,
                "metadata": doc.metadata
            }
            for doc in langchain_docs
        ]
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )
